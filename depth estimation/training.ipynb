{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install ultralytics OpenEXR Imath\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import OpenEXR\n",
        "import Imath\n",
        "import numpy as np\n",
        "\n",
        "def read_exr_file(file_path):\n",
        "    # Open the EXR file\n",
        "    exr_file = OpenEXR.InputFile(file_path)\n",
        "\n",
        "    # Get the header to extract basic information like resolution\n",
        "    header = exr_file.header()\n",
        "    dw = header['dataWindow']\n",
        "    width = dw.max.x - dw.min.x + 1\n",
        "    height = dw.max.y - dw.min.y + 1\n",
        "\n",
        "    # Print the channel names\n",
        "    channels = header['channels'].keys()\n",
        "    print(f\"Channels: {channels}\")\n",
        "\n",
        "    # Initialize a dictionary to hold the channel data\n",
        "    channel_data = {}\n",
        "\n",
        "    # Read all the channels present in the EXR file\n",
        "    for channel in channels:\n",
        "        channel_str = exr_file.channel(channel, Imath.PixelType(Imath.PixelType.FLOAT))\n",
        "        channel_data[channel] = np.frombuffer(channel_str, dtype=np.float32).reshape((height, width))\n",
        "\n",
        "    # If the file contains RGB channels, merge them into a single image\n",
        "    if 'R' in channels and 'G' in channels and 'B' in channels:\n",
        "        img = np.stack([channel_data['B'], channel_data['G'], channel_data['R']], axis=-1)\n",
        "    else:\n",
        "        raise ValueError(\"RGB channels not found in the EXR file.\")\n",
        "\n",
        "    return img\n",
        "\n",
        "model = YOLO(\"/content/best-150.pt\")\n",
        "\n",
        "\n",
        "\n",
        "#image in predict2, text in predict2/labels\n",
        "\n",
        "#results = model(\"/content/First.png\")\n",
        "model.predict(\"/content/00104Left.png\", save=True,save_txt=True, conf=0.3)\n",
        "img=cv2.imread(\"/content/runs/detect/predict18/00104Left.png\")\n",
        "f=open(\"/content/runs/detect/predict18/labels/00104Left.txt\")\n",
        "s=len(img)\n",
        "\n",
        "dep = read_exr_file(\"/content/00104Left.exr\")\n",
        "\n",
        "dep=cv2.cvtColor(dep,cv2.COLOR_BGR2GRAY)\n",
        "'''for i in range(s):             #trace between inf and non-inf\n",
        "  for j in range(s):\n",
        "    if dep[j,i]<10000000:\n",
        "      cv2.circle(img,(i,j),2,(255,0,0),thickness=-1)\n",
        "      break'''\n",
        "\n",
        "count=1\n",
        "while True:\n",
        "  #print(\"hhhh\")\n",
        "  line =f.readline()\n",
        "  if not line:\n",
        "    break\n",
        "  l=line.split(\" \")\n",
        "  #print(l)\n",
        "  (x,y)=(int((float(l[1]))*s),int((float(l[2]))*s))\n",
        "  #cv2.circle(img,(x,y),3,(255,0,0),thickness=-1)\n",
        "\n",
        "  if (dep[y,x]>=10000000000):\n",
        "    cv2.putText(img,\"inf\",(x-10,y+10),fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=0.6,color=(255,255,255),thickness=1)\n",
        "  else:\n",
        "    cv2.putText(img,str(round(dep[y,x],2)),(x-10,y+10),fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=0.6,color=(255,255,255),thickness=1)\n",
        "  print(count, x, y, dep[y,x])\n",
        "  count+=1\n",
        "\n",
        "cv2.imwrite(\"zamn.png\",img)\n",
        "\n",
        "#print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWyG8WcNdpDf",
        "outputId": "fef4ba97-4669-4626-b003-72e29a5a434a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/00104Left.png: 640x640 12 rocks, 298.4ms\n",
            "Speed: 7.5ms preprocess, 298.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict18\u001b[0m\n",
            "1 label saved to runs/detect/predict18/labels\n",
            "Channels: dict_keys(['B', 'G', 'R'])\n",
            "1 426 460 1.5296326\n",
            "2 159 485 1.1076856\n",
            "3 221 344 3.2535963\n",
            "4 65 371 2.6483903\n",
            "5 154 360 2.848288\n",
            "6 268 220 5.5714436\n",
            "7 393 250 5.146155\n",
            "8 396 341 3.3529038\n",
            "9 13 301 4.081373\n",
            "10 246 279 4.4526434\n",
            "11 288 339 3.3308377\n",
            "12 456 253 4.787533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}